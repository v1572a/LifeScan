{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8zBhWUlerCv",
        "outputId": "21fabdc7-20fc-4ecb-9edb-aad3da3b8623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Quantization complete. Saved to: classifier_int8.onnx\n"
          ]
        }
      ],
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "# Path to the original float32 model\n",
        "input_model_path = \"/content/cnn_model.onnx\"\n",
        "\n",
        "# Path to save the quantized int8 model\n",
        "output_model_path = \"classifier_int8.onnx\"\n",
        "\n",
        "# Perform dynamic quantization\n",
        "quantize_dynamic(\n",
        "    model_input=input_model_path,\n",
        "    model_output=output_model_path,\n",
        "    weight_type=QuantType.QInt8  # Or QuantType.QUInt8 for unsigned\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Quantization complete. Saved to:\", output_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnxruntime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxtu6k0xgUGp",
        "outputId": "10efc8d1-7495-4b74-bdaf-6db64862ec5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m358.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m709.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m615.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaQopzHDgoy2",
        "outputId": "5912c1de-66fa-42e2-a39c-618790fc2247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "model = onnx.load(\"/content/auto_int8.onnx\")\n",
        "\n",
        "# Check initializers (weights)\n",
        "for tensor in model.graph.initializer:\n",
        "    print(f\"{tensor.name}: {onnx.TensorProto.DataType.Name(tensor.data_type)}\")\n",
        "\n",
        "# Optional: Check input/output types too\n",
        "for input in model.graph.input:\n",
        "    print(f\"Input {input.name}: {input.type}\")\n",
        "for output in model.graph.output:\n",
        "    print(f\"Output {output.name}: {output.type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj21WLW0g6Hc",
        "outputId": "0f0dcfd6-ef1f-4964-ead6-11e33aa17c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "functional_1/conv2d_4_1/Squeeze:0: FLOAT\n",
            "functional_1/conv2d_3_1/Squeeze:0: FLOAT\n",
            "functional_1/conv2d_2_1/Squeeze:0: FLOAT\n",
            "functional_1/conv2d_1_2/Squeeze:0: FLOAT\n",
            "functional_1/conv2d_1/Squeeze:0: FLOAT\n",
            "const_fold_opt__55__58: INT64\n",
            "const_fold_opt__51: INT64\n",
            "const_fold_opt__47: INT64\n",
            "const_fold_opt__45: INT64\n",
            "const_fold_opt__43__57: INT64\n",
            "const_fold_opt__42: INT64\n",
            "functional_1/conv2d_1/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "functional_1/conv2d_1/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "functional_1/conv2d_1/convolution/ReadVariableOp:0_quantized: INT8\n",
            "functional_1/conv2d_1/BiasAdd:0_bias_reshape_shape: INT64\n",
            "functional_1/conv2d_1_2/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "functional_1/conv2d_1_2/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "functional_1/conv2d_1_2/convolution/ReadVariableOp:0_quantized: INT8\n",
            "functional_1/conv2d_1_2/BiasAdd:0_bias_reshape_shape: INT64\n",
            "functional_1/conv2d_2_1/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "functional_1/conv2d_2_1/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "functional_1/conv2d_2_1/convolution/ReadVariableOp:0_quantized: INT8\n",
            "functional_1/conv2d_2_1/BiasAdd:0_bias_reshape_shape: INT64\n",
            "functional_1/conv2d_3_1/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "functional_1/conv2d_3_1/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "functional_1/conv2d_3_1/convolution/ReadVariableOp:0_quantized: INT8\n",
            "functional_1/conv2d_3_1/BiasAdd:0_bias_reshape_shape: INT64\n",
            "functional_1/conv2d_4_1/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "functional_1/conv2d_4_1/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "functional_1/conv2d_4_1/convolution/ReadVariableOp:0_quantized: INT8\n",
            "functional_1/conv2d_4_1/BiasAdd:0_bias_reshape_shape: INT64\n",
            "Input args_0: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 64\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 64\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 3\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Output Identity:0: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 64\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 64\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 3\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import CalibrationDataReader\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class MyCalibrationDataReader(CalibrationDataReader):\n",
        "    def __init__(self, image_dir, input_name):\n",
        "        self.image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg'))]\n",
        "        self.input_name = input_name\n",
        "        self.data = []\n",
        "        for img_path in self.image_paths:\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (64, 64))\n",
        "            img = img.astype(np.float32) / 255.0  # adjust as per your normalization\n",
        "            img = np.expand_dims(img, axis=0)\n",
        "            self.data.append({self.input_name: img})\n",
        "        self.idx = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.idx >= len(self.data):\n",
        "            return None\n",
        "        item = self.data[self.idx]\n",
        "        self.idx += 1\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "VY7Ux9TEhZeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_static, QuantType\n",
        "import onnx\n",
        "\n",
        "# Load ONNX model\n",
        "model = onnx.load(\"/content/autoencoder_model.onnx\")\n",
        "input_name = model.graph.input[0].name\n",
        "\n",
        "# Initialize reader\n",
        "reader = MyCalibrationDataReader(\"path_to_sample_images\", input_name)\n",
        "\n",
        "quantize_static(\n",
        "    model_input=\"/content/autoencoder_model.onnx\",\n",
        "    model_output=\"auto_static_int8.onnx\",\n",
        "    calibration_data_reader=reader,\n",
        "    quant_format=\"QOperator\",\n",
        "    activation_type=QuantType.QInt8,\n",
        "    weight_type=QuantType.QInt8,\n",
        "    optimize_model=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "zYgpmuWYmA9U",
        "outputId": "41ed9d8f-3f18-4cf6-fbfd-443c64913025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path_to_sample_images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fdea6ee64d48>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Initialize reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyCalibrationDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path_to_sample_images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m quantize_static(\n",
            "\u001b[0;32m<ipython-input-10-017c2bd27e55>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, input_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMyCalibrationDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCalibrationDataReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_sample_images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5d1zGLOdmBAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Unzip the dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/onnx_.zip'         # <- Your zip file path\n",
        "extract_path = '/content/onnx_calibration_images'       # <- Extract location\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extracted files:\", os.listdir(extract_path)[:5])  # Print some filenames to check\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y09bS2vwmBFN",
        "outputId": "993af5e0-383c-45ab-db52-add562a844a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files: ['onnx_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CalibrationDataReader\n",
        "from onnxruntime.quantization import CalibrationDataReader\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class MyCalibrationDataReader(CalibrationDataReader):\n",
        "    def __init__(self, image_dir, input_name):\n",
        "        self.image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg'))]\n",
        "        self.input_name = input_name\n",
        "        self.data = []\n",
        "        for img_path in self.image_paths:\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (64, 64))\n",
        "            img = img.astype(np.float32) / 255.0\n",
        "            img = np.expand_dims(img, axis=0)   # add batch dim (NCHW)\n",
        "            self.data.append({self.input_name: img})\n",
        "        self.idx = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.idx >= len(self.data):\n",
        "            return None\n",
        "        item = self.data[self.idx]\n",
        "        self.idx += 1\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "Pfl2qGB1uNug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Static Quantization\n",
        "from onnxruntime.quantization import quantize_static, QuantType\n",
        "import onnx\n",
        "\n",
        "# Load the original ONNX model\n",
        "model = onnx.load(\"/content/cnn_model.onnx\")\n",
        "input_name = model.graph.input[0].name\n",
        "\n",
        "# Initialize calibration data reader\n",
        "reader = MyCalibrationDataReader(\"/content/onnx_calibration_images/onnx_\", input_name)\n",
        "\n",
        "# Run quantization\n",
        "quantize_static(\n",
        "    model_input=\"/content/cnn_model.onnx\",\n",
        "    model_output=\"/content/classifier_static_int8.onnx\",\n",
        "    calibration_data_reader=reader,\n",
        "    quant_format=\"QOperator\",\n",
        "    activation_type=QuantType.QInt8,\n",
        "    weight_type=QuantType.QInt8\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Quantized model saved as classifier_static_int8.onnx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mve1aliEuakz",
        "outputId": "04e8cc5d-37f2-4149-fb45-7fd026ba6370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
            "WARNING:root:Please use QuantFormat.QDQ for activation type QInt8 and weight type QInt8. Or it will lead to bad performance on x64.\n",
            "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model saved as classifier_static_int8.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import onnx\n",
        "\n",
        "model = onnx.load(\"/content/classifier_static_int8.onnx\")\n",
        "\n",
        "# Check initializers (weights)\n",
        "for tensor in model.graph.initializer:\n",
        "    print(f\"{tensor.name}: {onnx.TensorProto.DataType.Name(tensor.data_type)}\")\n",
        "\n",
        "# Optional: Check input/output types too\n",
        "for input in model.graph.input:\n",
        "    print(f\"Input {input.name}: {input.type}\")\n",
        "for output in model.graph.output:\n",
        "    print(f\"Output {output.name}: {output.type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSVqKnnuucfD",
        "outputId": "04531eb8-df1a-4c3e-b669-012ae34470dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "const_fold_opt__77: INT64\n",
            "sequential_1/conv2d_5_1/BiasAdd__64:0_zero_point: INT8\n",
            "sequential_1/conv2d_5_1/BiasAdd__64:0_scale: FLOAT\n",
            "sequential_1/conv2d_5_1/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "sequential_1/conv2d_5_1/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "sequential_1/conv2d_5_1/convolution/ReadVariableOp:0_quantized: INT8\n",
            "sequential_1/conv2d_5_1/Relu:0_zero_point: INT8\n",
            "sequential_1/conv2d_5_1/Relu:0_scale: FLOAT\n",
            "sequential_1/conv2d_6_1/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "sequential_1/conv2d_6_1/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "sequential_1/conv2d_6_1/convolution/ReadVariableOp:0_quantized: INT8\n",
            "sequential_1/conv2d_6_1/Relu:0_zero_point: INT8\n",
            "sequential_1/conv2d_6_1/Relu:0_scale: FLOAT\n",
            "sequential_1/conv2d_7_1/convolution/ReadVariableOp:0_zero_point: INT8\n",
            "sequential_1/conv2d_7_1/convolution/ReadVariableOp:0_scale: FLOAT\n",
            "sequential_1/conv2d_7_1/convolution/ReadVariableOp:0_quantized: INT8\n",
            "sequential_1/conv2d_7_1/Relu:0_zero_point: INT8\n",
            "sequential_1/conv2d_7_1/Relu:0_scale: FLOAT\n",
            "sequential_1/dense_1/Cast/ReadVariableOp:0_zero_point: INT8\n",
            "sequential_1/dense_1/Cast/ReadVariableOp:0_scale: FLOAT\n",
            "sequential_1/dense_1/Cast/ReadVariableOp:0_quantized: INT8\n",
            "sequential_1/dense_1/Relu:0_zero_point: INT8\n",
            "sequential_1/dense_1/Relu:0_scale: FLOAT\n",
            "sequential_1/dense_1_2/MatMul_Gemm__63:0_zero_point: INT8\n",
            "sequential_1/dense_1_2/MatMul_Gemm__63:0_scale: FLOAT\n",
            "sequential_1/dense_1_2/Cast/ReadVariableOp:0_zero_point: INT8\n",
            "sequential_1/dense_1_2/Cast/ReadVariableOp:0_scale: FLOAT\n",
            "sequential_1/dense_1_2/Cast/ReadVariableOp:0_quantized: INT8\n",
            "Identity:0_zero_point: INT8\n",
            "Identity:0_scale: FLOAT\n",
            "sequential_1/conv2d_5_1/Squeeze:0_quantized: INT32\n",
            "sequential_1/conv2d_5_1/Squeeze:0_quantized_scale: FLOAT\n",
            "sequential_1/conv2d_5_1/Squeeze:0_quantized_zero_point: INT32\n",
            "sequential_1/conv2d_6_1/Squeeze:0_quantized: INT32\n",
            "sequential_1/conv2d_6_1/Squeeze:0_quantized_scale: FLOAT\n",
            "sequential_1/conv2d_6_1/Squeeze:0_quantized_zero_point: INT32\n",
            "sequential_1/conv2d_7_1/Squeeze:0_quantized: INT32\n",
            "sequential_1/conv2d_7_1/Squeeze:0_quantized_scale: FLOAT\n",
            "sequential_1/conv2d_7_1/Squeeze:0_quantized_zero_point: INT32\n",
            "sequential_1/dense_1/BiasAdd/ReadVariableOp:0_quantized: INT32\n",
            "sequential_1/dense_1/BiasAdd/ReadVariableOp:0_quantized_scale: FLOAT\n",
            "sequential_1/dense_1/BiasAdd/ReadVariableOp:0_quantized_zero_point: INT32\n",
            "sequential_1/dense_1_2/BiasAdd/ReadVariableOp:0_quantized: INT32\n",
            "sequential_1/dense_1_2/BiasAdd/ReadVariableOp:0_quantized_scale: FLOAT\n",
            "sequential_1/dense_1_2/BiasAdd/ReadVariableOp:0_quantized_zero_point: INT32\n",
            "Input args_0: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 64\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 64\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 3\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "Output Identity:0: tensor_type {\n",
            "  elem_type: 1\n",
            "  shape {\n",
            "    dim {\n",
            "      dim_value: 1\n",
            "    }\n",
            "    dim {\n",
            "      dim_value: 7\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the model\n",
        "model_path = \"/content/auto_int8.onnx\"  # Change to your actual model path\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "def inspect_operator_dtypes(model):\n",
        "    fp32_nodes = []\n",
        "    int32_nodes = []\n",
        "    int8_nodes = []\n",
        "    other_nodes = []\n",
        "\n",
        "    for node in model.graph.node:\n",
        "        # Convert protobuf containers to lists first\n",
        "        input_names = list(node.input)\n",
        "        output_names = list(node.output)\n",
        "        all_names = input_names + output_names\n",
        "\n",
        "        # Check for known type indicators in names (common with quantized models)\n",
        "        if any(\"int8\" in name.lower() for name in all_names):\n",
        "            int8_nodes.append(node)\n",
        "        elif any(\"int32\" in name.lower() for name in all_names):\n",
        "            int32_nodes.append(node)\n",
        "        elif any(\"float\" in name.lower() or \"fp32\" in name.lower() for name in all_names):\n",
        "            fp32_nodes.append(node)\n",
        "        else:\n",
        "            other_nodes.append(node)\n",
        "\n",
        "    print(f\"üß† FP32 nodes: {len(fp32_nodes)}\")\n",
        "    print(f\"üßÆ INT32 nodes: {len(int32_nodes)}\")\n",
        "    print(f\"üì¶ INT8 nodes: {len(int8_nodes)}\")\n",
        "    print(f\"‚ùì Other nodes: {len(other_nodes)}\")\n",
        "\n",
        "    print(\"\\nüîç Sample FP32 Ops:\")\n",
        "    for node in fp32_nodes[:10]:  # show just first 10\n",
        "        print(f\" - {node.op_type} (name: {node.name})\")\n",
        "\n",
        "inspect_operator_dtypes(model)"
      ],
      "metadata": {
        "id": "KfnVl4RayYpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6696056a-a2d0-4324-b820-8c16dbf2427e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† FP32 nodes: 0\n",
            "üßÆ INT32 nodes: 0\n",
            "üì¶ INT8 nodes: 0\n",
            "‚ùì Other nodes: 60\n",
            "\n",
            "üîç Sample FP32 Ops:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRZFmx_6G534",
        "outputId": "cf62fc39-1934-4cca-b5d7-d9f40883aaca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the model\n",
        "model_path = \"/content/classifier_int8.onnx\"  # Change to your actual model path\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "def inspect_operator_dtypes(model):\n",
        "    fp32_nodes = []\n",
        "    int32_nodes = []\n",
        "    int8_nodes = []\n",
        "    other_nodes = []\n",
        "\n",
        "    for node in model.graph.node:\n",
        "        # Convert protobuf containers to lists first\n",
        "        input_names = list(node.input)\n",
        "        output_names = list(node.output)\n",
        "        all_names = input_names + output_names\n",
        "\n",
        "        # Check for known type indicators in names (common with quantized models)\n",
        "        if any(\"int8\" in name.lower() for name in all_names):\n",
        "            int8_nodes.append(node)\n",
        "        elif any(\"int32\" in name.lower() for name in all_names):\n",
        "            int32_nodes.append(node)\n",
        "        elif any(\"float\" in name.lower() or \"fp32\" in name.lower() for name in all_names):\n",
        "            fp32_nodes.append(node)\n",
        "        else:\n",
        "            other_nodes.append(node)\n",
        "\n",
        "    print(f\"üß† FP32 nodes: {len(fp32_nodes)}\")\n",
        "    print(f\"üßÆ INT32 nodes: {len(int32_nodes)}\")\n",
        "    print(f\"üì¶ INT8 nodes: {len(int8_nodes)}\")\n",
        "    print(f\"‚ùì Other nodes: {len(other_nodes)}\")\n",
        "\n",
        "    print(\"\\nüîç Sample FP32 Ops:\")\n",
        "    for node in fp32_nodes[:10]:  # show just first 10\n",
        "        print(f\" - {node.op_type} (name: {node.name})\")\n",
        "\n",
        "inspect_operator_dtypes(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izJos3SzG0Fc",
        "outputId": "69e1da77-8508-46c8-90a4-b61facd51c48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† FP32 nodes: 0\n",
            "üßÆ INT32 nodes: 0\n",
            "üì¶ INT8 nodes: 0\n",
            "‚ùì Other nodes: 44\n",
            "\n",
            "üîç Sample FP32 Ops:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the model\n",
        "model_path = \"/content/auto_static_int8.onnx\"  # Change to your actual model path\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "def inspect_operator_dtypes(model):\n",
        "    fp32_nodes = []\n",
        "    int32_nodes = []\n",
        "    int8_nodes = []\n",
        "    other_nodes = []\n",
        "\n",
        "    for node in model.graph.node:\n",
        "        # Convert protobuf containers to lists first\n",
        "        input_names = list(node.input)\n",
        "        output_names = list(node.output)\n",
        "        all_names = input_names + output_names\n",
        "\n",
        "        # Check for known type indicators in names (common with quantized models)\n",
        "        if any(\"int8\" in name.lower() for name in all_names):\n",
        "            int8_nodes.append(node)\n",
        "        elif any(\"int32\" in name.lower() for name in all_names):\n",
        "            int32_nodes.append(node)\n",
        "        elif any(\"float\" in name.lower() or \"fp32\" in name.lower() for name in all_names):\n",
        "            fp32_nodes.append(node)\n",
        "        else:\n",
        "            other_nodes.append(node)\n",
        "\n",
        "    print(f\"üß† FP32 nodes: {len(fp32_nodes)}\")\n",
        "    print(f\"üßÆ INT32 nodes: {len(int32_nodes)}\")\n",
        "    print(f\"üì¶ INT8 nodes: {len(int8_nodes)}\")\n",
        "    print(f\"‚ùì Other nodes: {len(other_nodes)}\")\n",
        "\n",
        "    print(\"\\nüîç Sample FP32 Ops:\")\n",
        "    for node in fp32_nodes[:10]:  # show just first 10\n",
        "        print(f\" - {node.op_type} (name: {node.name})\")\n",
        "\n",
        "inspect_operator_dtypes(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYMHI5BzHsV0",
        "outputId": "9e4584cd-b5b9-4dad-9496-ece6380c2c53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† FP32 nodes: 0\n",
            "üßÆ INT32 nodes: 0\n",
            "üì¶ INT8 nodes: 0\n",
            "‚ùì Other nodes: 64\n",
            "\n",
            "üîç Sample FP32 Ops:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx import mapping\n",
        "\n",
        "model_path = \"/content/auto_int8.onnx\"\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "def dtype_str(tensor_type):\n",
        "    \"\"\"Return the data type name from ONNX tensor type enum.\"\"\"\n",
        "    return mapping.TENSOR_TYPE_TO_NP_TYPE.get(tensor_type, \"UNKNOWN\")\n",
        "\n",
        "def print_tensor_dtypes(model):\n",
        "    all_tensors = (\n",
        "        list(model.graph.initializer) +\n",
        "        list(model.graph.input) +\n",
        "        list(model.graph.output) +\n",
        "        list(model.graph.value_info)\n",
        "    )\n",
        "\n",
        "    dtype_counts = {}\n",
        "    for tensor in all_tensors:\n",
        "        try:\n",
        "            # Handle initializer differently\n",
        "            if hasattr(tensor, 'data_type'):\n",
        "                dtype = tensor.data_type\n",
        "            else:\n",
        "                dtype = tensor.type.tensor_type.elem_type\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        dtype_name = dtype_str(dtype)\n",
        "        dtype_counts[dtype_name] = dtype_counts.get(dtype_name, 0) + 1\n",
        "\n",
        "    print(\"üìä Tensor Data Type Counts:\")\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\" - {dtype}: {count}\")\n",
        "\n",
        "print_tensor_dtypes(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NMCBVkeH3Gb",
        "outputId": "b242a92c-d07e-4c8d-b81a-e60706cb45ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Tensor Data Type Counts:\n",
            " - float32: 41\n",
            " - int64: 11\n",
            " - int8: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx import mapping\n",
        "\n",
        "model_path = \"/content/auto_static_int8.onnx\"\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "def dtype_str(tensor_type):\n",
        "    \"\"\"Return the data type name from ONNX tensor type enum.\"\"\"\n",
        "    return mapping.TENSOR_TYPE_TO_NP_TYPE.get(tensor_type, \"UNKNOWN\")\n",
        "\n",
        "def print_tensor_dtypes(model):\n",
        "    all_tensors = (\n",
        "        list(model.graph.initializer) +\n",
        "        list(model.graph.input) +\n",
        "        list(model.graph.output) +\n",
        "        list(model.graph.value_info)\n",
        "    )\n",
        "\n",
        "    dtype_counts = {}\n",
        "    for tensor in all_tensors:\n",
        "        try:\n",
        "            # Handle initializer differently\n",
        "            if hasattr(tensor, 'data_type'):\n",
        "                dtype = tensor.data_type\n",
        "            else:\n",
        "                dtype = tensor.type.tensor_type.elem_type\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        dtype_name = dtype_str(dtype)\n",
        "        dtype_counts[dtype_name] = dtype_counts.get(dtype_name, 0) + 1\n",
        "\n",
        "    print(\"üìä Tensor Data Type Counts:\")\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\" - {dtype}: {count}\")\n",
        "\n",
        "print_tensor_dtypes(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rq9eHPUIBWO",
        "outputId": "7f9f059f-16ca-4712-e8f2-e96904276a8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Tensor Data Type Counts:\n",
            " - int64: 6\n",
            " - int8: 19\n",
            " - float32: 50\n",
            " - int32: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx import mapping\n",
        "\n",
        "model_path = \"/content/classifier_int8.onnx\"\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "def dtype_str(tensor_type):\n",
        "    \"\"\"Return the data type name from ONNX tensor type enum.\"\"\"\n",
        "    return mapping.TENSOR_TYPE_TO_NP_TYPE.get(tensor_type, \"UNKNOWN\")\n",
        "\n",
        "def print_tensor_dtypes(model):\n",
        "    all_tensors = (\n",
        "        list(model.graph.initializer) +\n",
        "        list(model.graph.input) +\n",
        "        list(model.graph.output) +\n",
        "        list(model.graph.value_info)\n",
        "    )\n",
        "\n",
        "    dtype_counts = {}\n",
        "    for tensor in all_tensors:\n",
        "        try:\n",
        "            # Handle initializer differently\n",
        "            if hasattr(tensor, 'data_type'):\n",
        "                dtype = tensor.data_type\n",
        "            else:\n",
        "                dtype = tensor.type.tensor_type.elem_type\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        dtype_name = dtype_str(dtype)\n",
        "        dtype_counts[dtype_name] = dtype_counts.get(dtype_name, 0) + 1\n",
        "\n",
        "    print(\"üìä Tensor Data Type Counts:\")\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\" - {dtype}: {count}\")\n",
        "\n",
        "print_tensor_dtypes(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBVxvDvjIMPV",
        "outputId": "a3c092f8-3123-4a00-895e-92c064d3b060"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Tensor Data Type Counts:\n",
            " - float32: 29\n",
            " - int64: 4\n",
            " - int8: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx import mapping\n",
        "\n",
        "model_path = \"/content/classifier_static_int8.onnx\"\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "def dtype_str(tensor_type):\n",
        "    \"\"\"Return the data type name from ONNX tensor type enum.\"\"\"\n",
        "    return mapping.TENSOR_TYPE_TO_NP_TYPE.get(tensor_type, \"UNKNOWN\")\n",
        "\n",
        "def print_tensor_dtypes(model):\n",
        "    all_tensors = (\n",
        "        list(model.graph.initializer) +\n",
        "        list(model.graph.input) +\n",
        "        list(model.graph.output) +\n",
        "        list(model.graph.value_info)\n",
        "    )\n",
        "\n",
        "    dtype_counts = {}\n",
        "    for tensor in all_tensors:\n",
        "        try:\n",
        "            # Handle initializer differently\n",
        "            if hasattr(tensor, 'data_type'):\n",
        "                dtype = tensor.data_type\n",
        "            else:\n",
        "                dtype = tensor.type.tensor_type.elem_type\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        dtype_name = dtype_str(dtype)\n",
        "        dtype_counts[dtype_name] = dtype_counts.get(dtype_name, 0) + 1\n",
        "\n",
        "    print(\"üìä Tensor Data Type Counts:\")\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\" - {dtype}: {count}\")\n",
        "\n",
        "print_tensor_dtypes(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn6_YodOJlW4",
        "outputId": "d58b6cff-3c10-4559-9df4-0fd32bae0829"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Tensor Data Type Counts:\n",
            " - int64: 1\n",
            " - int8: 17\n",
            " - float32: 34\n",
            " - int32: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import psutil\n",
        "import logging\n",
        "from PIL import Image\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from memory_profiler import memory_usage\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Suppress logging\n",
        "logging.getLogger('onnxruntime').setLevel(logging.ERROR)\n",
        "\n",
        "# Define label dictionary (example)\n",
        "label_dict = {0: \"arm\", 1: \"elbow\", 2: \"face\", 3: \"foot\", 4: \"hand\", 5: \"leg\", 6: \"random\"}\n",
        "\n",
        "# Paths to your models\n",
        "onnx_original = \"/content/cnn_model.onnx\"\n",
        "onnx_quantized = \"/content/classifier_int8.onnx\"\n",
        "\n",
        "# Helper to unzip folder\n",
        "def unzip_folder(zip_path, extract_to=\"dataset\"):\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    return extract_to\n",
        "\n",
        "# Preprocess image (resize and normalize)\n",
        "def preprocess_image(image_path, size=(64, 64)):\n",
        "    img = Image.open(image_path).convert(\"RGB\").resize(size)\n",
        "    img = np.array(img, dtype=np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Run inference on ONNX model\n",
        "def run_onnx_inference(session, input_data):\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    outputs = session.run(None, {input_name: input_data})\n",
        "    return outputs[0]\n",
        "\n",
        "# Measure inference time, RAM, and CPU usage\n",
        "def measure_inference(func, *args):\n",
        "    process = psutil.Process()\n",
        "    start_time = time.time()\n",
        "    start_cpu = process.cpu_percent(interval=None)\n",
        "    mem_usage = memory_usage((func, args), interval=0.1, max_usage=True)\n",
        "    result = func(*args)\n",
        "    end_time = time.time()\n",
        "    end_cpu = process.cpu_percent(interval=None)\n",
        "    exec_time = (end_time - start_time) * 1000  # milliseconds\n",
        "    normalized_cpu = ((end_cpu + start_cpu) / 2) / psutil.cpu_count()\n",
        "    return mem_usage, normalized_cpu, exec_time, result\n",
        "\n",
        "# Load ONNX models\n",
        "def create_session(model_path):\n",
        "    try:\n",
        "        return ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "sess_orig = create_session(onnx_original)\n",
        "sess_quant = create_session(onnx_quantized)\n",
        "\n",
        "# Load image paths from unzipped folder\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []  # You should provide corresponding labels for the images\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(folder, filename)\n",
        "            images.append(image_path)\n",
        "            label = int(filename.split(\"_\")[0])  # Assuming label is part of filename (e.g., \"0_arm.jpg\")\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Load images from folder\n",
        "zip_path = \"/content/onnx_.zip\"  # Replace with your zip file path\n",
        "dataset_folder = unzip_folder(zip_path)\n",
        "image_paths, true_labels = load_images_from_folder(dataset_folder)\n",
        "\n",
        "# Inference and evaluation\n",
        "def evaluate_model(model_session, image_paths, true_labels):\n",
        "    preds = []\n",
        "    for img_path in image_paths:\n",
        "        img_data = preprocess_image(img_path)\n",
        "        pred = run_onnx_inference(model_session, img_data)\n",
        "        preds.append(np.argmax(pred))  # Predicted class\n",
        "    return accuracy_score(true_labels, preds)\n",
        "\n",
        "# Evaluate original and quantized models\n",
        "print(\"Evaluating Original Model...\")\n",
        "accuracy_orig = evaluate_model(sess_orig, image_paths, true_labels)\n",
        "print(f\"Original Model Accuracy: {accuracy_orig * 100:.2f}%\")\n",
        "\n",
        "print(\"Evaluating Quantized Model...\")\n",
        "accuracy_quant = evaluate_model(sess_quant, image_paths, true_labels)\n",
        "print(f\"Quantized Model Accuracy: {accuracy_quant * 100:.2f}%\")\n",
        "\n",
        "# Inference metrics for both models\n",
        "def inference_metrics():\n",
        "    print(\"\\nOriginal Model Inference Metrics:\")\n",
        "    try:\n",
        "        mem_orig, cpu_orig, time_orig, pred_orig = measure_inference(inference_original)\n",
        "        print(f\"  RAM={mem_orig:.2f} MB, CPU={cpu_orig:.2f}%, Time={time_orig:.2f} ms\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Failed: {str(e)}\")\n",
        "        exit(1)\n",
        "\n",
        "    print(\"\\nQuantized Model Inference Metrics:\")\n",
        "    try:\n",
        "        mem_quant, cpu_quant, time_quant, pred_quant = measure_inference(inference_quantized)\n",
        "        print(f\"  RAM={mem_quant:.2f} MB, CPU={cpu_quant:.2f}%, Time={time_quant:.2f} ms\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Failed: {str(e)}\")\n",
        "        exit(1)\n",
        "\n",
        "# Plot some examples (show original and predicted labels)\n",
        "def plot_results(image_paths, true_labels, preds):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(5):  # Show 5 examples\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        img = Image.open(image_paths[i])\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"True: {label_dict[true_labels[i]]}\\nPred: {label_dict[preds[i]]}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage of plotting the results for 5 images\n",
        "plot_results(image_paths, true_labels, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "wsUclVvbJric",
        "outputId": "f8442e30-bde4-4a9c-ad0b-d29f46fc2e0e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load model: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for ConvInteger(10) node with name 'sequential_1/conv2d_5_1/BiasAdd_quant'\n",
            "Evaluating Original Model...\n",
            "Original Model Accuracy: nan%\n",
            "Evaluating Quantized Model...\n",
            "Quantized Model Accuracy: nan%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preds' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3b52ba5627f3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# Example usage of plotting the results for 5 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHMmEQoHL0zp",
        "outputId": "7b53a0d6-acbb-4e15-f490-1875999f7c85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory_profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "\n",
        "# Define label dictionary (example)\n",
        "label_dict = {0: \"arm\", 1: \"elbow\", 2: \"face\", 3: \"foot\", 4: \"hand\", 5: \"leg\", 6: \"random\"}\n",
        "\n",
        "# Paths to your models\n",
        "onnx_original = \"/content/cnn_model.onnx\"\n",
        "onnx_quantized = \"/content/classifier_static_int8.onnx\"\n",
        "\n",
        "# Helper to unzip folder\n",
        "def unzip_folder(zip_path, extract_to=\"dataset\"):\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    return extract_to\n",
        "\n",
        "# Preprocess image (resize and normalize)\n",
        "def preprocess_image(image_path, size=(64, 64)):\n",
        "    img = Image.open(image_path).convert(\"RGB\").resize(size)\n",
        "    img = np.array(img, dtype=np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Run inference on ONNX model\n",
        "def run_onnx_inference(session, input_data):\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    outputs = session.run(None, {input_name: input_data})\n",
        "    return outputs[0]\n",
        "\n",
        "# Load ONNX models\n",
        "def create_session(model_path):\n",
        "    try:\n",
        "        return ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "sess_orig = create_session(onnx_original)\n",
        "sess_quant = create_session(onnx_quantized)\n",
        "\n",
        "# Load image paths from unzipped folder\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []  # You should provide corresponding labels for the images\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(folder, filename)\n",
        "            images.append(image_path)\n",
        "            label = int(filename.split(\"_\")[0])  # Assuming label is part of filename (e.g., \"0_arm.jpg\")\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Load images from folder\n",
        "zip_path = \"/content/onnx_.zip\"  # Replace with your zip file path\n",
        "dataset_folder = unzip_folder(zip_path)\n",
        "image_paths, true_labels = load_images_from_folder(dataset_folder)\n",
        "\n",
        "# Evaluate model accuracy\n",
        "def evaluate_model(model_session, image_paths, true_labels):\n",
        "    preds = []\n",
        "    for img_path in image_paths:\n",
        "        img_data = preprocess_image(img_path)\n",
        "        pred = run_onnx_inference(model_session, img_data)\n",
        "        preds.append(np.argmax(pred))  # Predicted class\n",
        "    accuracy = accuracy_score(true_labels, preds)\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate original and quantized models\n",
        "print(\"Evaluating Original Model...\")\n",
        "accuracy_orig = evaluate_model(sess_orig, image_paths, true_labels)\n",
        "print(f\"Original Model Accuracy: {accuracy_orig * 100:.2f}%\")\n",
        "\n",
        "print(\"Evaluating Quantized Model...\")\n",
        "accuracy_quant = evaluate_model(sess_quant, image_paths, true_labels)\n",
        "print(f\"Quantized Model Accuracy: {accuracy_quant * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyrp-h6IL5zq",
        "outputId": "d23210ac-0e94-4884-bcf2-7117af88e657"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Original Model...\n",
            "Original Model Accuracy: nan%\n",
            "Evaluating Quantized Model...\n",
            "Quantized Model Accuracy: nan%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "\n",
        "# Define label dictionary (example)\n",
        "label_dict = {0: \"arm\", 1: \"elbow\", 2: \"face\", 3: \"foot\", 4: \"hand\", 5: \"leg\", 6: \"random\"}\n",
        "\n",
        "# Paths to your models\n",
        "onnx_original = \"/content/cnn_model.onnx\"\n",
        "onnx_quantized = \"/content/classifier_static_int8.onnx\"\n",
        "\n",
        "# Helper to unzip folder\n",
        "def unzip_folder(zip_path, extract_to=\"dataset\"):\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    return extract_to\n",
        "\n",
        "# Preprocess image (resize and normalize)\n",
        "def preprocess_image(image_path, size=(64, 64)):\n",
        "    img = Image.open(image_path).convert(\"RGB\").resize(size)\n",
        "    img = np.array(img, dtype=np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Run inference on ONNX model\n",
        "def run_onnx_inference(session, input_data):\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    outputs = session.run(None, {input_name: input_data})\n",
        "    return outputs[0]\n",
        "\n",
        "# Load ONNX models\n",
        "def create_session(model_path):\n",
        "    try:\n",
        "        return ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "sess_orig = create_session(onnx_original)\n",
        "sess_quant = create_session(onnx_quantized)\n",
        "\n",
        "# Load image paths and labels from unzipped folder\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []  # Labels are assigned based on subfolder names (e.g., '0_arm')\n",
        "    class_labels = {cls: idx for idx, cls in label_dict.items()}\n",
        "\n",
        "    for class_name in os.listdir(folder):\n",
        "        class_folder = os.path.join(folder, class_name)\n",
        "\n",
        "        if os.path.isdir(class_folder):\n",
        "            for filename in os.listdir(class_folder):\n",
        "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                    image_path = os.path.join(class_folder, filename)\n",
        "                    images.append(image_path)\n",
        "                    label = class_labels[class_name]  # Use folder name to assign label\n",
        "                    labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Load images from folder\n",
        "zip_path = \"/content/natural_images.zip\"  # Replace with your zip file path\n",
        "dataset_folder = unzip_folder(zip_path)\n",
        "image_paths, true_labels = load_images_from_folder(dataset_folder)\n",
        "\n",
        "# Debug: Print out number of images and labels\n",
        "print(f\"Loaded {len(image_paths)} images.\")\n",
        "print(f\"Loaded {len(true_labels)} labels.\")\n",
        "\n",
        "# Evaluate model accuracy\n",
        "def evaluate_model(model_session, image_paths, true_labels):\n",
        "    preds = []\n",
        "    for img_path in image_paths:\n",
        "        img_data = preprocess_image(img_path)\n",
        "        pred = run_onnx_inference(model_session, img_data)\n",
        "\n",
        "        # Debug: Check model output\n",
        "        print(f\"Prediction for {img_path}: {pred}\")\n",
        "\n",
        "        preds.append(np.argmax(pred))  # Predicted class\n",
        "\n",
        "    # Debug: Check predictions and true labels\n",
        "    print(f\"Predictions: {preds}\")\n",
        "    print(f\"True Labels: {true_labels}\")\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, preds)\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate original and quantized models\n",
        "print(\"Evaluating Original Model...\")\n",
        "accuracy_orig = evaluate_model(sess_orig, image_paths, true_labels)\n",
        "print(f\"Original Model Accuracy: {accuracy_orig * 100:.2f}%\")\n",
        "\n",
        "print(\"Evaluating Quantized Model...\")\n",
        "accuracy_quant = evaluate_model(sess_quant, image_paths, true_labels)\n",
        "print(f\"Quantized Model Accuracy: {accuracy_quant * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "Ez4471JnM_pg",
        "outputId": "9f755996-1068-4e0d-b3f7-862cdf664434"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'onnx_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5d8986bb8ad8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/natural_images.zip\"\u001b[0m  \u001b[0;31m# Replace with your zip file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mdataset_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munzip_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Debug: Print out number of images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5d8986bb8ad8>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Use folder name to assign label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'onnx_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "\n",
        "# Define label dictionary (example)\n",
        "label_dict = {0: \"arm\", 1: \"elbow\", 2: \"face\", 3: \"foot\", 4: \"hand\", 5: \"leg\", 6: \"random\"}\n",
        "\n",
        "# Paths to your models\n",
        "onnx_original = \"/content/cnn_model.onnx\"\n",
        "onnx_quantized = \"/content/classifier_int8.onnx\"\n",
        "\n",
        "# Helper to unzip folder\n",
        "def unzip_folder(zip_path, extract_to=\"dataset\"):\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    return extract_to\n",
        "\n",
        "# Preprocess image (resize and normalize)\n",
        "def preprocess_image(image_path, size=(64, 64)):\n",
        "    img = Image.open(image_path).convert(\"RGB\").resize(size)\n",
        "    img = np.array(img, dtype=np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Run inference on ONNX model\n",
        "def run_onnx_inference(session, input_data):\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    outputs = session.run(None, {input_name: input_data})\n",
        "    return outputs[0]\n",
        "\n",
        "# Load ONNX models\n",
        "def create_session(model_path):\n",
        "    try:\n",
        "        return ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load model: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "sess_orig = create_session(onnx_original)\n",
        "sess_quant = create_session(onnx_quantized)\n",
        "\n",
        "# Load image paths and labels from unzipped folder\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []  # Labels are assigned based on subfolder names (e.g., '0_arm')\n",
        "    class_labels = {cls: idx for idx, cls in label_dict.items()}\n",
        "\n",
        "    # Debug: Print out all folders inside the dataset\n",
        "    print(f\"Found folders: {os.listdir(folder)}\")\n",
        "\n",
        "    for class_name in os.listdir(folder):\n",
        "        class_folder = os.path.join(folder, class_name)\n",
        "\n",
        "        # Check if the folder is a directory and if it belongs to the label dictionary\n",
        "        if os.path.isdir(class_folder):\n",
        "            if class_name in class_labels:\n",
        "                print(f\"Processing class: {class_name}\")\n",
        "                for filename in os.listdir(class_folder):\n",
        "                    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                        image_path = os.path.join(class_folder, filename)\n",
        "                        images.append(image_path)\n",
        "                        label = class_labels[class_name]  # Use folder name to assign label\n",
        "                        labels.append(label)\n",
        "            else:\n",
        "                print(f\"Skipping unknown class folder: {class_name}\")\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Load images from folder\n",
        "zip_path = \"/content/natural_images.zip\"  # Replace with your zip file path\n",
        "dataset_folder = unzip_folder(zip_path)\n",
        "image_paths, true_labels = load_images_from_folder(dataset_folder)\n",
        "\n",
        "# Debug: Print out number of images and labels\n",
        "print(f\"Loaded {len(image_paths)} images.\")\n",
        "print(f\"Loaded {len(true_labels)} labels.\")\n",
        "\n",
        "# Evaluate model accuracy\n",
        "def evaluate_model(model_session, image_paths, true_labels):\n",
        "    preds = []\n",
        "    for img_path in image_paths:\n",
        "        img_data = preprocess_image(img_path)\n",
        "        pred = run_onnx_inference(model_session, img_data)\n",
        "\n",
        "        # Debug: Check model output\n",
        "        print(f\"Prediction for {img_path}: {pred}\")\n",
        "\n",
        "        preds.append(np.argmax(pred))  # Predicted class\n",
        "\n",
        "    # Debug: Check predictions and true labels\n",
        "    print(f\"Predictions: {preds}\")\n",
        "    print(f\"True Labels: {true_labels}\")\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, preds)\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate original and quantized models\n",
        "print(\"Evaluating Original Model...\")\n",
        "accuracy_orig = evaluate_model(sess_orig, image_paths, true_labels)\n",
        "print(f\"Original Model Accuracy: {accuracy_orig * 100:.2f}%\")\n",
        "\n",
        "print(\"Evaluating Quantized Model...\")\n",
        "accuracy_quant = evaluate_model(sess_quant, image_paths, true_labels)\n",
        "print(f\"Quantized Model Accuracy: {accuracy_quant * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nj0SBLmPVui",
        "outputId": "d6ef5dfb-673e-46ae-dcd6-e89ddaf5e787"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load model: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for ConvInteger(10) node with name 'sequential_1/conv2d_5_1/BiasAdd_quant'\n",
            "Found folders: ['natural_images', 'onnx_']\n",
            "Skipping unknown class folder: natural_images\n",
            "Skipping unknown class folder: onnx_\n",
            "Loaded 0 images.\n",
            "Loaded 0 labels.\n",
            "Evaluating Original Model...\n",
            "Predictions: []\n",
            "True Labels: []\n",
            "Original Model Accuracy: nan%\n",
            "Evaluating Quantized Model...\n",
            "Predictions: []\n",
            "True Labels: []\n",
            "Quantized Model Accuracy: nan%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:557: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6u9CYSFBRLCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}